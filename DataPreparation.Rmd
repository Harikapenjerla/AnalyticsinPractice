---
title: "DataExploration"
output:
  word_document: default
  html_document: default
date: "2/25/2020"
---

Excercise-1
The Open Data 500 is the first comprehensive study of U.S. companies that use open government data to
generate new business and develop new products and services. Open Data is free, public data that can be
used to launch commercial and nonprofit ventures, conduct research, make data-driven decisions, and solve
complex problems [https://www.opendata500.com/]
In this assignment you will be analyzing two datasets – “US_agency.csv” and US_companies.csv”. You
can download the data from the website:
https://www.opendata500.com/
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Libraries Used in this two excercises for data preparation including r-essential bundle are
```{r}
library(tidyverse)
library(jsonlite)
library(dplyr)
```

Import two datasets
In order to emphasis the difference between read.csv and read_csv used two methods.
```{r}
data1 <- read.csv("us_agencies.csv")
data2 <- read.csv("us_companies.csv")
#data1 <- read_csv("us_agencies.csv")
#data2 <- read_csv("us_companies.csv")
```

1) Structure of the datasets
```{r}
str(data1)
str(data2)
```
1)No missing columns in both us_agencies and us_companies datasets.

2) colnames function
```{r}
colnames(data1)
colnames(data2)
```

no missing columns names or errors in the colummn names.

3)Finding missing values
INitially converting empty column values to NA
```{r}
data1[data1 == ""] <- NA
sapply(data1,function(x) sum(is.na(x)))
sum(is.na(data1))

data2[data2 == ""] <- NA
sapply(data2,function(x) sum(is.na(x)))
sum(is.na(data2))
```
Us_agencies (data1) has  2718 missing values
us_companies (data2) has 2315 missing values

4)Data is not organized in us_agencies and us_companies since some columns are not significant and too many categorical variables.  

5)Data is not in good shape for further analysis.
In dataset like us_agenies: 
columns like dataset_url has many missing values.
used_by_fte data is not organized.

In datasetlike us_companies: 
columns like full_time_ employees,source_count,data_impacts has unreadable characters and is not properly parsed.
financial_info has lot of missing values almost 73%.


6)Before doing any further analysis we need to do data preprocessing which involves steps like 
Finding:
dulplicate values in dataset.
Outliers
missing values 
Correlation between variables.

```{r}
#Finding Distinct values
data1_clean <- data1 %>% unique()
data2_clean <- data2 %>% unique()
```

Missing values can be impute by using some of the techniques as knn-imputation,mean,median.Some of the Libraries like Amelia,Hmisc,MICE can be used to deal with missing values.

7) There is primary key to connect two datasets.Having unique indentifier is needed for further analysis of two datasets.
In my opinion dataset of us_companies has column company_name can be used as primary key which has unique value since in us_agencies has used_by column which is using this values.


Exercise-2
JSON (JavaScript Object Notation) is a most commonly used data format today and as a data scientist, you
must know how to access JSON data sets. JSON is easy for machines to parse and generate. “It is based on
a subset of the JavaScript Programming Language Standard ECMA-262 3rd Edition - December 1999.
JSON is a text format that is completely language independent [JSON.ORG].”
For this case study, you will parse JSON file, which has city traffic details. “Average Daily Traffic (ADT)”
counts are analogous to a census count of vehicles on city streets. These counts provide a close
approximation to the actual number of vehicles passing through a given location on an average weekday.
Since it is not possible to count every vehicle on every city street, sample counts are taken along larger
streets to get an estimate of traffic on half-mile or one-mile street segments. ADT counts are used by city
planners, transportation engineers, real-estate developers, marketers and many others for myriad planning
and operational purposes. Data Owner: Transportation. Time Period: 2006. Frequency: A citywide count is taken approximately every 10 years. A limited number of traffic counts will be taken and added to the list periodically [https://catalog.data.gov/]”.
```{r}
datafile <- fromJSON("ChicagoTraffic.json")

```

 23 Variables in our dataset
```{r}
print(nrow(datafile$meta$view$columns))
```

To name all variables in json file using 
```{r}
print(datafile$meta$view$columns$name)
```


3)Total traffic of vechicle on 100 to 115 street
```{r}
traffic <- datafile$data

for(i in 1:1279){
  if(traffic[[i]][[11]] == "100th St"){
    print(as.numeric(traffic[[i]][[13]]))
  }
  if(traffic[[i]][[11]] == "101th St"){
    print(as.numeric(traffic[[i]][[13]]))
  }
  if(traffic[[i]][[11]] == "102th St"){
    print(as.numeric(traffic[[i]][[13]]))
  }
  if(traffic[[i]][[11]] == "103th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "104th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "105th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "106th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
   if(traffic[[i]][[11]] == "107th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "108th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "109th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "110th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "111th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "112th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "113th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "114th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
  if(traffic[[i]][[11]] == "115th St"){
    print(as.numeric(traffic[[i]][[13]]))
    }
}
```

4) total traffic of vehicles on geolocations, (41.651861, -87.54501) and (41.66836, -87.620176) is 13600
```{r}
for(j in 1:1279){
  if(traffic[[j]][[15]]=="41.651861" && traffic[[j]][[16]]== "-87.54501"){t1<-as.numeric(traffic[[j]][[13]])}
  if(traffic[[j]][[15]]=="41.66836" && traffic[[j]][[16]]== "-87.620176"){t2<-as.numeric(traffic[[j]][[13]])}
}
Total_Traffic=t1+t2
print(Total_Traffic)
```


